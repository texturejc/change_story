{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2546ca3f-530d-4ef2-85f8-6c17c7d8306f",
   "metadata": {},
   "source": [
    "# Personality, language, and the articulation of change\n",
    "\n",
    "![Alt Text](changes.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673b6099-ea85-4657-8de4-a0435b6dcbff",
   "metadata": {},
   "source": [
    "## Our questions:\n",
    "\n",
    "* Can we predict personality type from the language used in change narratives?\n",
    "* Can we predict language used in change narratives from personality type?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cc9f06-debd-4451-a3b5-2fbec96e7c7a",
   "metadata": {},
   "source": [
    "## Step 1: Data cleaning and Big 5 extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64dfc16-c3c9-47de-8346-3f2afbe2a212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_excel(\"Personal Change Questionnaire(1-28).xlsx\")\n",
    "data = data.dropna(axis = 1, how = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52c2327-28cb-4dc0-8c99-c463576e5b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['ID', 'Start time', 'Completion time', 'Email',\n",
    "       'nickname',\n",
    "       'gender', 'religion', 'freedom',\n",
    "       'Is talkative', 'Tends to find fault with others',\n",
    "       'Does a thorough job', 'Is depressed, blue',\n",
    "       'Is original, comes up with new ideas', 'Is reserved',\n",
    "       'Is helpful and unselfish with others', 'Can be somewhat careless',\n",
    "       'Is relaxed, can handle stress well',\n",
    "       'Is curious about many different things', 'Is full of energy',\n",
    "       'Starts quarrels with others', 'Is a reliable worker', 'Can be tense',\n",
    "       'Is ingenious, a deep thinker', 'Generates a lot of enthusiasm',\n",
    "       'Has a forgiving nature', 'Tends to be disorganised', 'Worries a lot',\n",
    "       'Has an active imagination', 'Tends to be quiet',\n",
    "       'Is generally trusting', 'Tends to be lazy',\n",
    "       'Is emotionally stable, not easily upset', 'Is inventive',\n",
    "       'Has an assertive personality', 'Can be cold and aloof',\n",
    "       'Perseveres until the task is finished', 'Can be moody',\n",
    "       'Values artistic, aesthetic experiences', 'Is sometimes shy, inhibited',\n",
    "       'Is considerate and kind to almost everyone', 'Does things efficiently',\n",
    "       'Remains calm in tense situations', 'Prefers work that is routine',\n",
    "       'Is outgoing, sociable', 'Is sometimes rude to others',\n",
    "       'Makes plans and follows through with them', 'Gets nervous easily',\n",
    "       'Likes to reflect, play with ideas', 'Has few artistic interests',\n",
    "       'Likes to cooperate with others', 'Is easily distracted',\n",
    "       'Is sophisticated in art, music, or literature',\n",
    "       'narrative',\n",
    "       'age',\n",
    "       'intensity',\n",
    "       'impact',\n",
    "       'publish']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e01442-ddcf-4ec9-ba64-e5314123b14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = data\n",
    "\n",
    "values_t = ['Disagree strongly','Disagree a little','Neither agree nor disagree','Agree a little','Agree strongly']\n",
    "\n",
    "values_n = [1,2,3,4,5]\n",
    "\n",
    "\n",
    "mapping = dict(zip(values_t, values_n))\n",
    "\n",
    "\n",
    "\n",
    "raw = raw.replace(mapping)\n",
    "\n",
    "def rev(col):\n",
    "    col_ = (5 - col) +1\n",
    "    return col_\n",
    "\n",
    "reversals = ['Is reserved', 'Tends to be quiet', 'Is sometimes shy, inhibited', 'Tends to find fault with others', 'Starts quarrels with others',\\\n",
    "             'Can be cold and aloof', 'Is sometimes rude to others', 'Can be somewhat careless', 'Tends to be disorganised',\\\n",
    "                 'Tends to be lazy', 'Is easily distracted', 'Is relaxed, can handle stress well', 'Is emotionally stable, not easily upset',\\\n",
    "                     'Remains calm in tense situations',  'Prefers work that is routine', 'Has few artistic interests']\n",
    "    \n",
    "for i in reversals:\n",
    "    raw[i] = rev(raw[i])\n",
    "    \n",
    "raw_numbered = raw[['Is talkative', 'Tends to find fault with others',\n",
    "       'Does a thorough job', 'Is depressed, blue',\n",
    "       'Is original, comes up with new ideas', 'Is reserved',\n",
    "       'Is helpful and unselfish with others', 'Can be somewhat careless',\n",
    "       'Is relaxed, can handle stress well',\n",
    "       'Is curious about many different things', 'Is full of energy',\n",
    "       'Starts quarrels with others', 'Is a reliable worker', 'Can be tense',\n",
    "       'Is ingenious, a deep thinker', 'Generates a lot of enthusiasm',\n",
    "       'Has a forgiving nature', 'Tends to be disorganised', 'Worries a lot',\n",
    "       'Has an active imagination', 'Tends to be quiet',\n",
    "       'Is generally trusting', 'Tends to be lazy',\n",
    "       'Is emotionally stable, not easily upset', 'Is inventive',\n",
    "       'Has an assertive personality', 'Can be cold and aloof',\n",
    "       'Perseveres until the task is finished', 'Can be moody',\n",
    "       'Values artistic, aesthetic experiences', 'Is sometimes shy, inhibited',\n",
    "       'Is considerate and kind to almost everyone', 'Does things efficiently',\n",
    "       'Remains calm in tense situations', 'Prefers work that is routine',\n",
    "       'Is outgoing, sociable', 'Is sometimes rude to others',\n",
    "       'Makes plans and follows through with them', 'Gets nervous easily',\n",
    "       'Likes to reflect, play with ideas', 'Has few artistic interests',\n",
    "       'Likes to cooperate with others', 'Is easily distracted',\n",
    "       'Is sophisticated in art, music, or literature']]\n",
    "\n",
    "nums = [str(i) for i in range(1,45)]\n",
    "\n",
    "raw_numbered.columns = nums\n",
    "\n",
    "\n",
    "E = pd.concat([raw_numbered['1'], raw_numbered['6'], raw_numbered['11'], raw_numbered['16'], raw_numbered['21'], raw_numbered['26'], raw_numbered['31'], raw_numbered['36']], axis = 1)\n",
    "\n",
    "A = pd.concat([raw_numbered['2'], raw_numbered['7'], raw_numbered['12'], raw_numbered['17'], raw_numbered['22'], raw_numbered['27'], raw_numbered['32'], raw_numbered['37'], raw_numbered['42']], axis = 1)\n",
    "\n",
    "C = pd.concat([raw_numbered['3'],  raw_numbered['8'], raw_numbered['13'], raw_numbered['18'], raw_numbered['23'], raw_numbered['28'], raw_numbered['33'], raw_numbered['38'], raw_numbered['43']], axis = 1)\n",
    "\n",
    "N = pd.concat([raw_numbered['4'],  raw_numbered['9'], raw_numbered['14'], raw_numbered['19'], raw_numbered['24'], raw_numbered['29'], raw_numbered['34'], raw_numbered['39']], axis = 1)\n",
    "\n",
    "O = pd.concat([raw_numbered['5'], raw_numbered['10'], raw_numbered['15'], raw_numbered['20'], raw_numbered['25'], raw_numbered['30'], raw_numbered['35'], raw_numbered['40'], raw_numbered['25'], raw_numbered['41'], raw_numbered['44']], axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "raw['extraversion'] = E.mean(axis = 1)\n",
    "raw['agreeableness'] = A.mean(axis = 1)\n",
    "raw['conscientiousness'] = C.mean(axis = 1)\n",
    "raw['neuroticism'] = N.mean(axis = 1)\n",
    "raw['openness'] = O.mean(axis = 1)\n",
    "\n",
    "raw = raw[['extraversion', 'agreeableness', 'conscientiousness', 'openness',\n",
    "       'neuroticism']]\n",
    "\n",
    "raw['nickname'] = data['nickname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd481ee9-1042-486c-b5ee-9a0db6b02c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw['religion'] = data['religion']\n",
    "raw['freedom'] = data['freedom']\n",
    "raw['narrative'] = data['narrative']\n",
    "raw['intensity'] = data['intensity']\n",
    "raw['age'] = data['age']\n",
    "raw = raw.replace(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b716e4-46c7-4a02-8b56-0e7ebb35c895",
   "metadata": {},
   "source": [
    "[![YouTube Video](https://img.youtube.com/vi/p0FdAM9knDo/0.jpg)](https://www.youtube.com/watch?v=p0FdAM9knDo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef1ef67-2734-4b49-b6fe-723192385c7b",
   "metadata": {},
   "source": [
    "## Step 2: Consolidation of Big 5 scores into stability and plasticity\n",
    "\n",
    "![Alt Text](superfactor.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf20abc-3bfb-4335-995e-93d3be5ef119",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "big_five = ['extraversion', 'agreeableness', 'conscientiousness', 'openness', 'neuroticism']\n",
    "five = raw[big_five]\n",
    "df_z = five.apply(zscore)\n",
    "\n",
    "# Calculate Stability and Plasticity\n",
    "five['stability'] = (\n",
    "    df_z['agreeableness'] +\n",
    "    df_z['conscientiousness'] +\n",
    "    (-df_z['neuroticism'])\n",
    ")\n",
    "\n",
    "five['plasticity'] = (\n",
    "    df_z['extraversion'] +\n",
    "    df_z['openness']\n",
    ")\n",
    "\n",
    "raw['plasticity'] = five['plasticity']\n",
    "raw['stability'] = five['stability']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6915fa-95e3-4736-b3d7-6b5a863d2843",
   "metadata": {},
   "source": [
    "[![YouTube Video](https://img.youtube.com/vi/sNgiN8hXK6M/0.jpg)](https://www.youtube.com/watch?v=sNgiN8hXK6M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e70d0f-ba56-4569-94ef-a42d5205c5a5",
   "metadata": {},
   "source": [
    "## Step 3: NLP analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dbf40e-1186-4bc5-bb00-c5d0462ef028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "!pip install pingouin\n",
    "!python -m spacy download en_core_web_md\n",
    "import pingouin as pg\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "import re\n",
    "import pingouin\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "nlp.vocab[\"\\n\"].is_stop = True\n",
    "nlp.max_length = 4353682\n",
    "\n",
    "def process(text):\n",
    "    parsed_text = nlp(text)\n",
    "    full_vocab = [token.lemma_.lower() for token in parsed_text \\\n",
    "                   if not token.is_stop and\\\n",
    "                   not token.is_punct\n",
    "                  #below I add some new criteria - CR\n",
    "                  and not token.text.strip() == ''       #remove empty text\n",
    "                  and token.is_ascii\n",
    "                  and re.match('[a-zA-Z]',token.text) #remove non ascii\n",
    "                  and not re.match('^[\\n]+$',token.text) #remove multiple line breaks\n",
    "                  and not token.like_url                 #remove urls\n",
    "                  and not '&nbsp' in token.text and not token.like_num]         # remove html garble\n",
    "    return full_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334ec5b8-febf-4668-ad39-f432acc96fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word norm data\n",
    "\n",
    "norms = pd.read_pickle(\"all_norm_estimates.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e6e911-63c8-4229-9aa0-0577e320a855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word norm functions\n",
    "\n",
    "def word_norms(text):\n",
    "    lemmas = process(text)\n",
    "\n",
    "    words = []\n",
    "    norms_ = []\n",
    "\n",
    "    for i in lemmas:\n",
    "        if i in norms.index:\n",
    "            norms_.append(norms.loc[i])\n",
    "            words.append(i)\n",
    "        else:\n",
    "            pass\n",
    "    norms_df = pd.DataFrame(norms, index = words)\n",
    "    return norms_df\n",
    "\n",
    "def word_norms_mean(text):\n",
    "    lemmas = process(text)\n",
    "\n",
    "    words = []\n",
    "    norms_ = []\n",
    "\n",
    "    for i in lemmas:\n",
    "        if i in norms.index:\n",
    "            norms_.append(norms.loc[i])\n",
    "            words.append(i)\n",
    "        else:\n",
    "            pass\n",
    "    norms_df = pd.DataFrame(norms_)\n",
    "    return norms_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad77daa3-d969-4c16-9230-f36243906403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract word norms\n",
    "\n",
    "tales = [i for i in raw['narrative']]\n",
    "norm = [word_norms_mean(i) for i in tales]\n",
    "norms_all = pd.DataFrame(norm)\n",
    "raw = pd.concat([raw, norms_all], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce0fb52-607e-44db-80bb-56f02f177c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get spaCy embeddings for each narrative\n",
    "\n",
    "vectors = [nlp(i).vector for i in raw['narrative']]\n",
    "vecs_df = pd.DataFrame(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ca2c1b-27f2-4c0b-81f2-ce022935c420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the the optimal number of components to use\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Fit PCA with many components first\n",
    "pca = PCA(n_components=28)  # or even larger\n",
    "X_pca = pca.fit_transform(vecs_df)\n",
    "\n",
    "# Plot cumulative explained variance\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_), marker='o')\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Cumulative explained variance')\n",
    "plt.title('Explained Variance vs. Number of Components')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477f1b3f-86e1-47c2-8317-47763246e3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the identified components to the data\n",
    "\n",
    "pca = PCA(n_components = 3)\n",
    "comps = pca.fit_transform(vecs_df)\n",
    "pc_df = pd.DataFrame(data = comps, columns = ['PC'+str(i) for i in range(1, comps.shape[1]+1)])\n",
    "raw = pd.concat([raw, pc_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b0d892-eeec-4efc-b122-c4b43deb1a11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(\n",
    "    raw,\n",
    "    x=\"PC1\",\n",
    "    y=\"PC2\",\n",
    "    z=\"PC3\",\n",
    "    hover_data=['nickname'],\n",
    "    color_discrete_sequence=['red']  # Force all markers to red\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Change narrratives Immersion Week 25 T3\",\n",
    "    paper_bgcolor=\"#343434\",  # Outer background\n",
    "    plot_bgcolor=\"#343434\",   # Should affect 2D plots, but 3D requires scene settings\n",
    "    font=dict(color='white'),\n",
    "    scene=dict(\n",
    "        xaxis=dict(\n",
    "            showgrid=True,\n",
    "            gridcolor='rgba(150, 150, 150, 0.5)',  # Light gray gridlines\n",
    "            #title= x,\n",
    "            backgroundcolor=\"#343434\"  # Match axis background\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            showgrid=True,\n",
    "            gridcolor='rgba(150, 150, 150, 0.5)',\n",
    "            #title= y,\n",
    "            backgroundcolor=\"#343434\"\n",
    "        ),\n",
    "        zaxis=dict(\n",
    "            showgrid=True,\n",
    "            gridcolor='rgba(150, 150, 150, 0.5)',\n",
    "            #title= z,\n",
    "            backgroundcolor=\"#343434\"\n",
    "        ),\n",
    "        bgcolor=\"#343434\"  # Critical: Sets the 3D plot's facecolor\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_traces(\n",
    "    marker=dict(\n",
    "        size=5,\n",
    "        color='red',  # Explicit red markers\n",
    "        opacity=0.8\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dec589-1599-409e-a36b-498a634affa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0779ef95-4009-4d9d-a643-5d82ed54241a",
   "metadata": {},
   "source": [
    "[![YouTube Video](https://img.youtube.com/vi/IJSv6JXKS_I/0.jpg)](https://www.youtube.com/watch?v=IJSv6JXKS_I)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5131de-ebdf-44dd-972a-a132b5ca7fd7",
   "metadata": {},
   "source": [
    "## Step 4: Some data science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b065034-934d-4090-bd8e-aab21f54f3a3",
   "metadata": {},
   "source": [
    "### OLS regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f4d9cb-503b-41b1-a779-35891e06a3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = pg.linear_regression(raw[['valence', 'arousal',\n",
    "       'dominance', 'auditory', 'gustatory', 'interoceptive', 'olfactory',\n",
    "       'visual', 'foot_leg', 'hand_arm', 'head', 'mouth', 'torso',\n",
    "       'concreteness', 'imageability', 'semantic_size', 'haptic']], raw['plasticity'])\n",
    "lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac6dd55-44f0-4a5e-8238-ada4b0ff7dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(raw[['valence', 'arousal',\n",
    "       'dominance', 'auditory', 'gustatory', 'interoceptive', 'olfactory',\n",
    "       'visual', 'foot_leg', 'hand_arm', 'head', 'mouth', 'torso',\n",
    "       'concreteness', 'imageability', 'semantic_size', 'haptic']].corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be94890a-3a0b-4a38-b280-8e2d86659988",
   "metadata": {},
   "source": [
    "### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bdecf7-ff74-44c6-b911-2928ffec8f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# Your predictors:\n",
    "X = raw[['valence', 'arousal', 'dominance', 'auditory', 'gustatory', 'interoceptive', 'olfactory', \n",
    "         'visual', 'foot_leg', 'hand_arm', 'head', 'mouth', 'torso',\n",
    "         'concreteness', 'imageability', 'semantic_size', 'haptic']]\n",
    "\n",
    "# Your DV:\n",
    "\n",
    "variable = 'stability'\n",
    "\n",
    "y = raw[variable]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882f39cc-f3f5-4969-ad57-5e62ed3f4600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RidgeCV automatically tunes alpha (regularization strength)\n",
    "ridge = RidgeCV(alphas=np.logspace(-3, 3, 100), cv=5)\n",
    "\n",
    "# Build pipeline: scaling is important for Ridge!\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Standardize predictors\n",
    "    ('ridge', ridge)\n",
    "])\n",
    "\n",
    "# Cross-validated R²\n",
    "cv_scores = cross_val_score(pipeline, X, y, cv=5, scoring='r2')\n",
    "\n",
    "print(f\"Mean CV R²: {cv_scores.mean():.3f} ± {cv_scores.std():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ec8a5f-0dc7-435d-8983-72085270b881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now fit final model on full data\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# Extract fitted RidgeCV from pipeline\n",
    "ridge_model = pipeline.named_steps['ridge']\n",
    "\n",
    "# Display coefficients in a nice table\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': ridge_model.coef_\n",
    "}).sort_values(by='Coefficient', key=abs, ascending=False)\n",
    "\n",
    "print(coef_df)\n",
    "\n",
    "# Plot coefficients (optional)\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(coef_df['Feature'], coef_df['Coefficient'])\n",
    "plt.xlabel('Ridge Coefficient')\n",
    "plt.title('Feature importance for '+variable+' (Ridge regression)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddeca83-db0c-457a-ba1d-11d034c4946e",
   "metadata": {},
   "source": [
    "[![YouTube Video](https://img.youtube.com/vi/n4RjJKxsamQ/0.jpg)](https://www.youtube.com/watch?v=n4RjJKxsamQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb0e6a3-e794-44bc-904a-6e63a59f2d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:NLP] *",
   "language": "python",
   "name": "conda-env-NLP-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
